{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460c6218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lifelines import CoxPHFitter\n",
    "import statistics\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "%run functions.py\n",
    "\n",
    "\n",
    "# load dataset\n",
    "df_new = pd.read_csv('dataset_with_all_vars_converted_to_numerical_values.csv')\n",
    "# determine the outcome label \n",
    "col_y='sab'\n",
    "\n",
    "# do the needed preparation\n",
    "## Center the “number of pregnancies” variable at the median for the gravid cohort\n",
    "median_numpregs = df_new['b_numpregs'].median()\n",
    "temp_numpregs = df_new.loc[(df_new['b_everpregnant']==1), 'b_numpregs']\n",
    "df_new.loc[(df_new['b_everpregnant']==1), 'b_numpregs'] = temp_numpregs - median_numpregs\n",
    "\n",
    "# Statistical Feature Selection (SFS) \n",
    "# step 1\n",
    "# drop variables wit std of zero\n",
    "df_std = df_new.std()\n",
    "drop_cols = df_std[df_std<0.001].index.values\n",
    "df_new = df_drop(df_new, drop_cols)\n",
    "\n",
    "# compute the variables statistics and save it in dataframe named \"result\"\n",
    "y = df_new[col_y].astype(int)\n",
    "result = stat_test(df_new, y)\n",
    "\n",
    "# step 2\n",
    "# Compute pairwise correlation of variables with each other and determine pairs with corr > 0.9\n",
    "# Compute the correlation of highly correlated pairs with outcome as well as their p-value\n",
    "# We remove one variable among highly correlated pairs\n",
    "selected_col_to_remove, df_highcorr = highcorr_stats(df_new, col_y, thres=0.9)\n",
    "df_new = df_drop(df_new, selected_col_to_remove)\n",
    "\n",
    "# step 3\n",
    "# We test the association between each variable and the outcome \n",
    "# Chi2 test is used for non-continuous variables, and KS test is used for continuous variables\n",
    "# We remove variables that are not independently associated with the outcome based on p-value > 0.05\n",
    "drop_cols = result.loc[result['p-value']>0.05,'Variable'].values\n",
    "df_new = df_drop(df_new, drop_cols)\n",
    "\n",
    "\n",
    "# SURVIVAL MODEL DEVELOPMENT \n",
    "\n",
    "# define variables we use in the model definition\n",
    "# in the format that cox model needs\n",
    "df_new['col_time'] = (df_new['censorweek'] - df_new['startweek']).astype(int)\n",
    "col_time = 'col_time'\n",
    "col_strata = 'startweek'\n",
    "# remove extra vars \n",
    "df_new = df_drop(df_new, ['censorweek'])\n",
    "\n",
    "# define X as the model's input\n",
    "X = df_new.drop([col_y, col_time, col_strata], axis=1)\n",
    "# store features' names for final report\n",
    "name_cols = df_new.drop([col_y, col_time, col_strata], axis=1).columns.values\n",
    "# Standardization\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "# Save the dataset with standardized features \n",
    "df = pd.DataFrame(X, columns=name_cols)\n",
    "df[col_y] = df_new[col_y]\n",
    "df[col_time] = df_new[col_time]\n",
    "df[col_strata] = df_new[col_strata]\n",
    "y = df[col_y].astype(int)\n",
    "\n",
    "# Split dataset to training set and testing set with test size of 0.2\n",
    "cph_train, cph_test = train_test_split(df, test_size=0.2, random_state=2020, stratify=y) \n",
    "\n",
    "# FULL MODEL\n",
    "# Train Cox model usig all variables\n",
    "cph = CoxPHFitter(penalizer=0.01)\n",
    "df_cph_train=pd.DataFrame(cph_train, columns=df.columns.tolist())\n",
    "cph.fit(df=df_cph_train, duration_col=col_time, event_col=col_y, strata=col_strata)\n",
    "\n",
    "# Report predictor variables' coefficients and hazard ratios based on CoxPH model\n",
    "df_coef_cox = cph.summary[['coef', 'exp(coef)', 'exp(coef) lower 95%', 'exp(coef) upper 95%']]\n",
    "df_coef_cox['Variable'] = df_coef_cox.index\n",
    "df_coef_cox['coef_abs'] = df_coef_cox['coef'].abs()\n",
    "df_coef_cox = pd.merge(df_coef_cox,result[['Variable','p-value']], how='left', on=['Variable'])\n",
    "LRresult_ = pd.merge(explain_Variables[['Variable','Label']],df_coef_cox.sort_values(by=['coef_abs'],ascending=False), how='right', on=['Variable'])\n",
    "LRresult_=LRresult_.drop(['coef_abs'], axis=1)\n",
    "print(LRresult_)\n",
    "\n",
    "# Run 5 times with 5  different random spliting of dataset\n",
    "# Report mean and std of models' concordance index on the testing set, over the 5 runs\n",
    "test_score = []\n",
    "train_score = []\n",
    "my_seeds=range(2020, 2025)\n",
    "for seed in my_seeds:  \n",
    "    cph_train, cph_test = train_test_split(df, test_size=0.2, random_state=seed, stratify=y) \n",
    "    df_cph_train = pd.DataFrame(X_train_y, columns=df.columns.tolist())\n",
    "    cph = CoxPHFitter(penalizer=0.01)\n",
    "    cph.fit(df=df_cph_train, duration_col=col_time, event_col=col_y, strata=col_strata)\n",
    "    train_score.append(cph.score(cph_train, scoring_method='concordance_index'))  \n",
    "    test_score.append(cph.score(cph_test, scoring_method='concordance_index'))\n",
    "print(f\"The mean (std) of Concordance Index of Full models, over the 5 runs, on training set is: {statistics.mean(train_score)} ({np.std(train_score)})\")\n",
    "print(f\"The mean (std) of Concordance Index of Full models, over the 5 runs, on testing set is: {statistics.mean(test_score)} ({np.std(test_score)})\")\n",
    "\n",
    "\n",
    "# SPARSE MODEL\n",
    "# Univariate Feature Selection \n",
    "# Compute Concordance Index for each variable based on training set and select top k variables \n",
    "y = df_cph_train[[col_y, col_time, col_strata]]\n",
    "X = df_cph_train.drop([col_y, col_time, col_strata], axis=1)\n",
    "n_features = X.shape[1]\n",
    "scores = np.empty(n_features)\n",
    "m = CoxPHFitter(penalizer=0.01)\n",
    "for j in range(n_features):\n",
    "    Xj = X.iloc[:, j:j+1]\n",
    "    Xj = pd.merge(Xj, y,  how='right', left_index=True, right_index=True)\n",
    "    m.fit(Xj, duration_col=col_time, event_col=col_y, strata=col_strata)\n",
    "    scores[j] = m.score(Xj, scoring_method='concordance_index')\n",
    "# Store variables and their associated concordance index \n",
    "df_predictors = pd.Series(scores, index=X.columns).sort_values(ascending=False)\n",
    "k=10 # number of variables we want to use in model \n",
    "top_predictors = df_predictors[0:k].index.tolist()\n",
    "# store the dataset of selected features in df_top\n",
    "df_top = df[top_predictors + [col_time, col_y, col_strata]]\n",
    "\n",
    "# Train Cox model usig selected variables\n",
    "cph = CoxPHFitter(penalizer=0.01)\n",
    "cph.fit(df=df_cph_train[top_predictors+ [col_time, col_y, col_strata]], duration_col=col_time, event_col=col_y, strata=col_strata)\n",
    "\n",
    "# Report predictor variables' coefficients and hazard ratios based on CoxPH model\n",
    "df_coef_cox = cph.summary[['coef', 'exp(coef)', 'exp(coef) lower 95%', 'exp(coef) upper 95%']]\n",
    "df_coef_cox['Variable'] = df_coef_cox.index\n",
    "df_coef_cox['coef_abs'] = df_coef_cox['coef'].abs()\n",
    "df_coef_cox = pd.merge(df_coef_cox,result[['Variable','p-value']], how='left', on=['Variable'])\n",
    "LRresult_ = pd.merge(explain_Variables[['Variable','Label']],df_coef_cox.sort_values(by=['coef_abs'],ascending=False), how='right', on=['Variable'])\n",
    "LRresult_=LRresult_.drop(['coef_abs'], axis=1)\n",
    "print(LRresult_)\n",
    "\n",
    "# Run 5 times with 5  different random spliting of dataset\n",
    "# Report mean and std of models' concordance index on the testing set, over the 5 runs\n",
    "test_score = []\n",
    "train_score = []\n",
    "for seed in my_seeds:  \n",
    "    cph_train, cph_test = train_test_split(df_top, test_size=0.2, random_state=seed, stratify=y) \n",
    "    df_cph_train = pd.DataFrame(X_train_y, columns=df.columns.tolist())\n",
    "    cph = CoxPHFitter(penalizer=0.01)\n",
    "    cph.fit(df=df_cph_train, duration_col=col_time, event_col=col_y, strata=col_strata)\n",
    "    train_score.append(cph.score(cph_train, scoring_method='concordance_index'))  \n",
    "    test_score.append(cph.score(cph_test, scoring_method='concordance_index'))    \n",
    "print(f\"The mean (std) of Concordance Index of Sparse models, over the 5 runs, on training set is: {statistics.mean(train_score)} ({np.std(train_score)})\")\n",
    "print(f\"The mean (std) of Concordance Index of Sparse models, over the 5 runs, on testing set is: {statistics.mean(test_score)} ({np.std(test_score)})\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
